struct SimpleGame
    Î³  # discount factor
    â„  # agents
    ğ’œ  # joint action space
    R  # joint reward function
end

using LinearAlgebra
using GridInterpolations
using CategoricalArrays
using Distributions
using Random



struct SimpleGamePolicy
    p # dictionary mapping actions to probabilities
    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end

    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k,v) in zip(keys(p), vs))) # return SimpleGamePolicy from dictionary
    end

    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))  # return SimpleGamePolicy with probability of ai is 1
end

(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)  # return probability agent i will do action ai

function (Ï€i::SimpleGamePolicy)()
    D = SetCategorical(collect(keys(Ï€i.p)), collect(values(Ï€i.p)))
    return rand(D)  # return random action
end
    
joint(X) = vec(collect(Iterators.product(X...)))  # construct joint action space from X
joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)]  # replace Ï€(i) with Ï€i

function utility(ğ’«::SimpleGame, Ï€, i)
    ğ’œ, R = ğ’«.ğ’œ, ğ’«.R
    p(a) = prod(Ï€j(aj) for (Ï€j, aj) in zip(Ï€, a))
    return sum(R(a)[i]*p(a) for a in joint(ğ’œ))  # the utility of agent i with joint policy Ï€
end